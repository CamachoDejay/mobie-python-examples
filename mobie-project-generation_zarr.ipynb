{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import os\n",
    "import imageio\n",
    "import mobie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of the input data. \n",
    "# the example data used in this notebook is available via this link:\n",
    "input_data_path = \"data\"\n",
    "\n",
    "# the location of the mobie project that will be created\n",
    "# we recommend that the mobie project folders have the structure <PROECJT_ROOT_FOLDER/data>\n",
    "# the folder 'data' will contain the sub-folders for individual datasets\n",
    "mobie_project_folder = \"mobie-project-01/data\"\n",
    "\n",
    "# name of the dataset that will be created.\n",
    "# one project can contain multiple datasets\n",
    "dataset_name = \"LM-dataset\"\n",
    "dataset_folder = os.path.join(mobie_project_folder, dataset_name)\n",
    "\n",
    "# the platform and number of jobs used for computation.\n",
    "# choose 'local' to run computations on your machine.\n",
    "# for large data, it is also possible to run computation on a cluster;\n",
    "# for this purpose 'slurm' (for slurm cluster) and 'lsf' (for lsf cluster) are currently supported\n",
    "target = \"local\"\n",
    "max_jobs = 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the dataset\n",
    "\n",
    "First, we need to initialize the dataset. This step includes generating the top-level project folder (if it's not present already), the subfolders for the new dataset and adding the \"default\" image for this dataset.\n",
    "All these steps are performed by the function `add_image`.\n",
    "\n",
    "This function accepts input image data in different formats. The input data is specified with the arguments\n",
    "`input_path`, which specifies the file path and `input_key`, which specifies the internal path or search patterns.\n",
    "- tif images (2d or 3d) - for this option set `input_key=''`\n",
    "- folder with image files - for this option `input_key` needs to be the glob pattern for the image files, e.g `input_key='*.tif'` to load all tif files\n",
    "- hdf5 file - `input_key` needs to be the internal file path\n",
    "- n5 or zarr file - `input_key` needs to be the internal file path\n",
    "\n",
    "The input files will be copied into the project folder in the [bdv.n5 dataformat](https://github.com/bigdataviewer/bigdataviewer-core/blob/master/BDV%20N5%20format.md) and an image pyramid will be created through consecutive downsampling.\n",
    "\n",
    "To efficiently process large files the inputs should be in hdf5, n5 or zarr format.\n",
    "Note that all inputs need to be either 2d or 3d images (volumes).\n",
    "Multi-channel images (volumes) should be seperated into their channels and then each channel added individually (see `Adding image data` below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xcamra\\anaconda3\\envs\\mobie2-env\\lib\\site-packages\\luigi\\parameter.py:279: UserWarning: Parameter \"dtype\" with value \"None\" is not of type string.\n",
      "  warnings.warn('Parameter \"{}\" with value \"{}\" is not of type string.'.format(param_name, param_value))\n",
      "DEBUG: Checking if DownscalingWorkflow(tmp_folder=tmp_LM-dataset_overview, max_jobs=4, config_dir=tmp_LM-dataset_overview\\configs, target=local, dependency=DummyTask, input_path=data\\blobs.ome.tif, input_key=, scale_factors=[[1, 2, 2], [1, 2, 2], [1, 2, 2], [1, 2, 2]], halos=[[1, 2, 2], [1, 2, 2], [1, 2, 2], [1, 2, 2]], dtype=None, int_to_uint=False, metadata_format=ome.zarr, metadata_dict={\"resolution\": [1.0, 454, 454], \"unit\": \"nanometer\", \"setup_name\": \"overview\"}, output_path=mobie-project-01/data\\LM-dataset\\images\\ome-zarr\\overview.ome.zarr, output_key_prefix=, force_copy=False, skip_existing_levels=False, scale_offset=0) is complete\n",
      "c:\\Users\\xcamra\\anaconda3\\envs\\mobie2-env\\lib\\site-packages\\luigi\\parameter.py:279: UserWarning: Parameter \"scale_factor\" with value \"(1, 2, 2)\" is not of type string.\n",
      "  warnings.warn('Parameter \"{}\" with value \"{}\" is not of type string.'.format(param_name, param_value))\n",
      "DEBUG: Checking if WriteDownscalingMetadata(tmp_folder=tmp_LM-dataset_overview, output_path=mobie-project-01/data\\LM-dataset\\images\\ome-zarr\\overview.ome.zarr, scale_factors=[[1, 2, 2], [1, 2, 2], [1, 2, 2], [1, 2, 2]], dependency=DownscalingLocal, metadata_format=ome.zarr, metadata_dict={\"resolution\": [1.0, 454, 454], \"unit\": \"nanometer\", \"setup_name\": \"overview\"}, output_key_prefix=, scale_offset=0, prefix=downscaling) is complete\n",
      "INFO: Informed scheduler that task   DownscalingWorkflow_tmp_LM_dataset_o_DummyTask_None_06ef2cfe91   has status   PENDING\n",
      "DEBUG: Checking if DownscalingLocal(tmp_folder=tmp_LM-dataset_overview, max_jobs=4, config_dir=tmp_LM-dataset_overview\\configs, input_path=mobie-project-01/data\\LM-dataset\\images\\ome-zarr\\overview.ome.zarr, input_key=s3, output_path=mobie-project-01/data\\LM-dataset\\images\\ome-zarr\\overview.ome.zarr, output_key=s4, scale_factor=(1, 2, 2), scale_prefix=s4, halo=[1, 2, 2], effective_scale_factor=[1, 16, 16], dimension_separator=/, dependency=DownscalingLocal) is complete\n",
      "INFO: Informed scheduler that task   WriteDownscalingMetadata_DownscalingLocal___resolution_____ome_zarr_07be573120   has status   PENDING\n",
      "DEBUG: Checking if DownscalingLocal(tmp_folder=tmp_LM-dataset_overview, max_jobs=4, config_dir=tmp_LM-dataset_overview\\configs, input_path=mobie-project-01/data\\LM-dataset\\images\\ome-zarr\\overview.ome.zarr, input_key=s2, output_path=mobie-project-01/data\\LM-dataset\\images\\ome-zarr\\overview.ome.zarr, output_key=s3, scale_factor=(1, 2, 2), scale_prefix=s3, halo=[1, 2, 2], effective_scale_factor=[1, 8, 8], dimension_separator=/, dependency=DownscalingLocal) is complete\n",
      "INFO: Informed scheduler that task   DownscalingLocal_tmp_LM_dataset_o_DownscalingLocal___10a042186d   has status   PENDING\n",
      "DEBUG: Checking if DownscalingLocal(tmp_folder=tmp_LM-dataset_overview, max_jobs=4, config_dir=tmp_LM-dataset_overview\\configs, input_path=mobie-project-01/data\\LM-dataset\\images\\ome-zarr\\overview.ome.zarr, input_key=s1, output_path=mobie-project-01/data\\LM-dataset\\images\\ome-zarr\\overview.ome.zarr, output_key=s2, scale_factor=(1, 2, 2), scale_prefix=s2, halo=[1, 2, 2], effective_scale_factor=[1, 4, 4], dimension_separator=/, dependency=DownscalingLocal) is complete\n",
      "INFO: Informed scheduler that task   DownscalingLocal_tmp_LM_dataset_o_DownscalingLocal___9959b76446   has status   PENDING\n",
      "DEBUG: Checking if DownscalingLocal(tmp_folder=tmp_LM-dataset_overview, max_jobs=4, config_dir=tmp_LM-dataset_overview\\configs, input_path=mobie-project-01/data\\LM-dataset\\images\\ome-zarr\\overview.ome.zarr, input_key=s0, output_path=mobie-project-01/data\\LM-dataset\\images\\ome-zarr\\overview.ome.zarr, output_key=s1, scale_factor=(1, 2, 2), scale_prefix=s1, halo=[1, 2, 2], effective_scale_factor=[1, 2, 2], dimension_separator=/, dependency=CopyVolumeLocal) is complete\n",
      "INFO: Informed scheduler that task   DownscalingLocal_tmp_LM_dataset_o_DownscalingLocal___8b1139f587   has status   PENDING\n",
      "DEBUG: Checking if CopyVolumeLocal(tmp_folder=tmp_LM-dataset_overview, max_jobs=4, config_dir=tmp_LM-dataset_overview\\configs, input_path=data\\blobs.ome.tif, input_key=, output_path=mobie-project-01/data\\LM-dataset\\images\\ome-zarr\\overview.ome.zarr, output_key=s0, prefix=initial_scale, dtype=None, int_to_uint=False, fit_to_roi=False, effective_scale_factor=[], dimension_separator=/, dependency=DummyTask) is complete\n",
      "INFO: Informed scheduler that task   DownscalingLocal_tmp_LM_dataset_o_CopyVolumeLocal___89b1c62693   has status   PENDING\n",
      "DEBUG: Checking if DummyTask() is complete\n",
      "INFO: Informed scheduler that task   CopyVolumeLocal_tmp_LM_dataset_o_DummyTask___8cc13cb6a8   has status   PENDING\n",
      "INFO: Informed scheduler that task   DummyTask__99914b932b   has status   DONE\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 7\n",
      "INFO: [pid 10340] Worker Worker(salt=552075641, workers=1, host=DESKTOP-T2QV97M, username=xcamra, pid=10340) running   CopyVolumeLocal(tmp_folder=tmp_LM-dataset_overview, max_jobs=4, config_dir=tmp_LM-dataset_overview\\configs, input_path=data\\blobs.ome.tif, input_key=, output_path=mobie-project-01/data\\LM-dataset\\images\\ome-zarr\\overview.ome.zarr, output_key=s0, prefix=initial_scale, dtype=None, int_to_uint=False, fit_to_roi=False, effective_scale_factor=[], dimension_separator=/, dependency=DummyTask)\n",
      "ERROR: [pid 10340] Worker Worker(salt=552075641, workers=1, host=DESKTOP-T2QV97M, username=xcamra, pid=10340) failed    CopyVolumeLocal(tmp_folder=tmp_LM-dataset_overview, max_jobs=4, config_dir=tmp_LM-dataset_overview\\configs, input_path=data\\blobs.ome.tif, input_key=, output_path=mobie-project-01/data\\LM-dataset\\images\\ome-zarr\\overview.ome.zarr, output_key=s0, prefix=initial_scale, dtype=None, int_to_uint=False, fit_to_roi=False, effective_scale_factor=[], dimension_separator=/, dependency=DummyTask)\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xcamra\\anaconda3\\envs\\mobie2-env\\lib\\site-packages\\luigi\\worker.py\", line 191, in run\n",
      "    new_deps = self._run_get_new_deps()\n",
      "  File \"c:\\Users\\xcamra\\anaconda3\\envs\\mobie2-env\\lib\\site-packages\\luigi\\worker.py\", line 133, in _run_get_new_deps\n",
      "    task_gen = self.task.run()\n",
      "  File \"c:\\Users\\xcamra\\anaconda3\\envs\\mobie2-env\\lib\\site-packages\\cluster_tools\\cluster_tasks.py\", line 95, in run\n",
      "    raise e\n",
      "  File \"c:\\Users\\xcamra\\anaconda3\\envs\\mobie2-env\\lib\\site-packages\\cluster_tools\\cluster_tasks.py\", line 81, in run\n",
      "    self.run_impl()\n",
      "  File \"c:\\Users\\xcamra\\anaconda3\\envs\\mobie2-env\\lib\\site-packages\\cluster_tools\\copy_volume\\copy_volume.py\", line 154, in run_impl\n",
      "    block_list = vu.blocks_in_volume(shape, block_shape, roi_begin, roi_end)\n",
      "  File \"c:\\Users\\xcamra\\anaconda3\\envs\\mobie2-env\\lib\\site-packages\\cluster_tools\\utils\\volume_utils.py\", line 46, in blocks_in_volume\n",
      "    assert len(shape) == len(block_shape), \"%i; %i\" % (len(shape), len(block_shape))\n",
      "AssertionError: 2; 3\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   CopyVolumeLocal_tmp_LM_dataset_o_DummyTask___8cc13cb6a8   has status   FAILED\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Done\n",
      "DEBUG: There are no more tasks to run at this time\n",
      "DEBUG: There are 7 pending tasks possibly being run by other workers\n",
      "DEBUG: There are 7 pending tasks unique to this worker\n",
      "DEBUG: There are 7 pending tasks last scheduled by this worker\n",
      "INFO: Worker Worker(salt=552075641, workers=1, host=DESKTOP-T2QV97M, username=xcamra, pid=10340) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 8 tasks of which:\n",
      "* 1 complete ones were encountered:\n",
      "    - 1 DummyTask()\n",
      "* 1 failed:\n",
      "    - 1 CopyVolumeLocal(...)\n",
      "* 6 were left pending, among these:\n",
      "    * 6 had failed dependencies:\n",
      "        - 4 DownscalingLocal(...)\n",
      "        - 1 DownscalingWorkflow(...)\n",
      "        - 1 WriteDownscalingMetadata(...)\n",
      "\n",
      "This progress looks :( because there were failed tasks\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Downscaling failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m chunks \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m, \u001b[39m64\u001b[39m, \u001b[39m64\u001b[39m)\n\u001b[0;32m     26\u001b[0m scale_factors \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\u001b[39m*\u001b[39m[[\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m]]\n\u001b[1;32m---> 28\u001b[0m mobie\u001b[39m.\u001b[39;49madd_image(\n\u001b[0;32m     29\u001b[0m     input_path\u001b[39m=\u001b[39;49minput_file, \n\u001b[0;32m     30\u001b[0m     input_key\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m,  \u001b[39m# the input is a single tif image, so we leave input_key blank\u001b[39;49;00m\n\u001b[0;32m     31\u001b[0m     root\u001b[39m=\u001b[39;49mmobie_project_folder,\n\u001b[0;32m     32\u001b[0m     dataset_name\u001b[39m=\u001b[39;49mdataset_name,\n\u001b[0;32m     33\u001b[0m     image_name\u001b[39m=\u001b[39;49mraw_name,\n\u001b[0;32m     34\u001b[0m     menu_name\u001b[39m=\u001b[39;49mmenu_name,\n\u001b[0;32m     35\u001b[0m     resolution\u001b[39m=\u001b[39;49mresolution,\n\u001b[0;32m     36\u001b[0m     chunks\u001b[39m=\u001b[39;49mchunks,\n\u001b[0;32m     37\u001b[0m     scale_factors\u001b[39m=\u001b[39;49mscale_factors,\n\u001b[0;32m     38\u001b[0m     is_default_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,  \u001b[39m# mark this dataset as the default dataset that will be loaded by mobie\u001b[39;49;00m\n\u001b[0;32m     39\u001b[0m     target\u001b[39m=\u001b[39;49mtarget,\n\u001b[0;32m     40\u001b[0m     max_jobs\u001b[39m=\u001b[39;49mmax_jobs,\n\u001b[0;32m     41\u001b[0m     unit\u001b[39m=\u001b[39;49munit,\n\u001b[0;32m     42\u001b[0m     file_format\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mome.zarr\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m     43\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\xcamra\\anaconda3\\envs\\mobie2-env\\lib\\site-packages\\mobie\\image_data.py:237\u001b[0m, in \u001b[0;36madd_image\u001b[1;34m(input_path, input_key, root, dataset_name, image_name, resolution, scale_factors, chunks, file_format, menu_name, tmp_folder, target, max_jobs, view, transformation, unit, is_default_dataset, description, move_only, int_to_uint, channel)\u001b[0m\n\u001b[0;32m    234\u001b[0m         shutil\u001b[39m.\u001b[39mmove(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplitext(input_path)[\u001b[39m0\u001b[39m]\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.xml\u001b[39m\u001b[39m\"\u001b[39m, image_metadata_path)\n\u001b[0;32m    236\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     import_image_data(input_path, input_key, data_path,\n\u001b[0;32m    238\u001b[0m                       resolution, scale_factors, chunks,\n\u001b[0;32m    239\u001b[0m                       tmp_folder\u001b[39m=\u001b[39;49mtmp_folder, target\u001b[39m=\u001b[39;49mtarget,\n\u001b[0;32m    240\u001b[0m                       max_jobs\u001b[39m=\u001b[39;49mmax_jobs, unit\u001b[39m=\u001b[39;49munit,\n\u001b[0;32m    241\u001b[0m                       source_name\u001b[39m=\u001b[39;49mimage_name,\n\u001b[0;32m    242\u001b[0m                       file_format\u001b[39m=\u001b[39;49mfile_format,\n\u001b[0;32m    243\u001b[0m                       int_to_uint\u001b[39m=\u001b[39;49mint_to_uint,\n\u001b[0;32m    244\u001b[0m                       channel\u001b[39m=\u001b[39;49mchannel)\n\u001b[0;32m    246\u001b[0m metadata\u001b[39m.\u001b[39madd_source_to_dataset(dataset_folder, \u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m, image_name, image_metadata_path,\n\u001b[0;32m    247\u001b[0m                                view\u001b[39m=\u001b[39mview, description\u001b[39m=\u001b[39mdescription, channel\u001b[39m=\u001b[39mchannel)\n\u001b[0;32m    249\u001b[0m \u001b[39mif\u001b[39;00m transformation \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\xcamra\\anaconda3\\envs\\mobie2-env\\lib\\site-packages\\mobie\\import_data\\image.py:35\u001b[0m, in \u001b[0;36mimport_image_data\u001b[1;34m(in_path, in_key, out_path, resolution, scale_factors, chunks, tmp_folder, target, max_jobs, block_shape, unit, source_name, file_format, int_to_uint, channel)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mif\u001b[39;00m file_format \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mome.zarr\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     34\u001b[0m     in_path, in_key \u001b[39m=\u001b[39m ensure_volume(in_path, in_key, tmp_folder, chunks)\n\u001b[1;32m---> 35\u001b[0m downscale(in_path, in_key, out_path,\n\u001b[0;32m     36\u001b[0m           resolution, scale_factors, chunks,\n\u001b[0;32m     37\u001b[0m           tmp_folder, target, max_jobs, block_shape,\n\u001b[0;32m     38\u001b[0m           library\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mskimage\u001b[39;49m\u001b[39m\"\u001b[39;49m, unit\u001b[39m=\u001b[39;49munit, source_name\u001b[39m=\u001b[39;49msource_name,\n\u001b[0;32m     39\u001b[0m           metadata_format\u001b[39m=\u001b[39;49mfile_format, int_to_uint\u001b[39m=\u001b[39;49mint_to_uint,\n\u001b[0;32m     40\u001b[0m           channel\u001b[39m=\u001b[39;49mchannel)\n",
      "File \u001b[1;32mc:\\Users\\xcamra\\anaconda3\\envs\\mobie2-env\\lib\\site-packages\\mobie\\import_data\\utils.py:105\u001b[0m, in \u001b[0;36mdownscale\u001b[1;34m(in_path, in_key, out_path, resolution, scale_factors, chunks, tmp_folder, target, max_jobs, block_shape, library, library_kwargs, metadata_format, out_key, unit, source_name, roi_begin, roi_end, int_to_uint, channel)\u001b[0m\n\u001b[0;32m    103\u001b[0m ret \u001b[39m=\u001b[39m luigi\u001b[39m.\u001b[39mbuild([t], local_scheduler\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ret:\n\u001b[1;32m--> 105\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDownscaling failed\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Downscaling failed"
     ]
    }
   ],
   "source": [
    "input_data_path = \"data\"\n",
    "# The 'default' image for our example dataset is a 2d EM slice showing an overview of the dataset.\n",
    "input_file = os.path.join(input_data_path, \"blobs.ome.tif\")\n",
    "\n",
    "# This is the name that will be given to the image source in mobie.\n",
    "raw_name = \"overview\"\n",
    "# The name of the menu from which the image can be added to the viewer.\n",
    "# Here, we choose \"em\", because this is an EM image slice.\n",
    "menu_name = \"lm\"\n",
    "\n",
    "# We need some metadata to create the n5-file in big-data-viewer format:\n",
    "# - unit: the phyiscal unit of the coordinate system\n",
    "# - resolution: the size of one voxel in the physical unit, this needs to be a tuple/list of length 3,\n",
    "#               specifying the size for each of the 3 spatial dimensions\n",
    "# - chunks: the size of the chunks (in voxels) that are used to store the output file.\n",
    "#           good choices are usually (1, 512, 512) for 2d data and (64, 64, 64) for 3d data\n",
    "# - scale_factors: the scale factors used for downsampling the input when creating the image pyramid\n",
    "#                  this needs to be a list, where each entry specifies the scale factors for the 3 axes.\n",
    "# Note that axes are listed in the order ZYX for the resolution, chunks and scale factors\n",
    "# (in the java implementation of mobie / big-data-viewer the axis convention is XYZ).\n",
    "# Also note that the values for all three axes (ZYX) need to be specified. In the case of 2d data, the value\n",
    "# for Z should be set to 1.\n",
    "unit = \"nanometer\"\n",
    "resolution = (1., 454, 454)\n",
    "chunks = (1, 64, 64)\n",
    "scale_factors = 4*[[1, 2, 2]]\n",
    "\n",
    "mobie.add_image(\n",
    "    input_path=input_file, \n",
    "    input_key='',  # the input is a single tif image, so we leave input_key blank\n",
    "    root=mobie_project_folder,\n",
    "    dataset_name=dataset_name,\n",
    "    image_name=raw_name,\n",
    "    menu_name=menu_name,\n",
    "    resolution=resolution,\n",
    "    chunks=chunks,\n",
    "    scale_factors=scale_factors,\n",
    "    is_default_dataset=True,  # mark this dataset as the default dataset that will be loaded by mobie\n",
    "    target=target,\n",
    "    max_jobs=max_jobs,\n",
    "    unit=unit,\n",
    "    file_format=\"ome.zarr\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = mobie.metadata.read_dataset_metadata(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[\"is2D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[\"is2D\"] = True\n",
    "mobie.metadata.write_dataset_metadata(dataset_folder, meta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mobie2-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb186d2f309bc00557b4f8909d5e887a9afffb683d5e77157fbe4b0332985f5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
